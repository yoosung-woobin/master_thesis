{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only required when running on gcloud datalab\n",
    "!pip install keras\n",
    "!pip install --update tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "a531416c78634aaee4e6171baa9c79a0c2f89414"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, CuDNNLSTM, Input, concatenate, Concatenate\n",
    "from keras.backend import clear_session\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor data from Professor Amit Goyal's Website (Welch and Goyal (2008))\n",
    "url = 'http://www.hec.unil.ch/agoyal/docs/PredictorData2017.xlsx'\n",
    "mn_df = pd.read_excel(url,index_col='yyyymm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a4f12b01f13e4d1e7785e54b58f90237949c689d"
   },
   "outputs": [],
   "source": [
    "# Data Loading Snippets from Google Cloud Datastorage\n",
    "# <Only used when running on Google Cloud Datalab>\n",
    "from google.datalab import storage\n",
    "from io import BytesIO\n",
    "mybucket = storage.Bucket('master_thesis_storage')\n",
    "data_ori = mybucket.object('mn_df_ori.csv')\n",
    "data_sqr = mybucket.object('mn_df_sqr.csv')\n",
    "data_asy = mybucket.object('mn_df_asy.csv')\n",
    "uri_ori = data_ori.uri\n",
    "uri_sqr = data_sqr.uri\n",
    "uri_asy = data_asy.uri\n",
    "%gcs read --object $uri_ori --variable data_ori\n",
    "mn_df_ori = pd.read_csv(BytesIO(data_ori))\n",
    "%gcs read --object $uri_sqr --variable data_sqr\n",
    "mn_df_sqr = pd.read_csv(BytesIO(data_sqr))\n",
    "%gcs read --object $uri_asy --variable data_asy\n",
    "mn_df_asy = pd.read_csv(BytesIO(data_asy))\n",
    "mn_df_ori.set_index('yyyymm', inplace=True)\n",
    "mn_df_sqr.set_index('yyyymm', inplace=True)\n",
    "mn_df_asy.set_index('yyyymm', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "56770daa811dc96e4f50c2e9f3351ad908526ba9"
   },
   "outputs": [],
   "source": [
    "# This cell contains all the dataset preparation, customized function\n",
    "def variable_deriv(df):    \n",
    "    #Yielding Equity Premium    \n",
    "    df['premium'] = np.log((df.Index+df.D12)/(df.Index.shift(periods=1)*(1+df.Rfree)))\n",
    "    #Yielding Indicator where its previous Return was positive\n",
    "    df['indicator'] = (df.premium.shift(periods=1)>0).apply(lambda x: 1 if x==True else 0)       \n",
    "    #Yielding Dividend Price Ratio\n",
    "    df['dp'] = np.log(df.D12) - np.log(df.Index)\n",
    "    #Yielding Divident Yield\n",
    "    df['dy'] = np.log(df.D12) - np.log(df.Index.shift(periods=1))\n",
    "    #Yielding Earnings Price Ratio\n",
    "    df['ep'] = np.log(df.E12) - np.log(df.Index)\n",
    "    #Yielding Divident Payout Ratio\n",
    "    df['de'] = np.log(df.D12) - np.log(df.E12)\n",
    "    #Yielding The Term Spread\n",
    "    df['tms'] = df.lty - df.tbl\n",
    "    #Yielding The Default Yield Spread\n",
    "    df['dfy'] = df.BAA - df.AAA\n",
    "    #Yielding The Default Return Spread\n",
    "    df['dfr'] = df.corpr - df.ltr\n",
    "################################################################################################################\n",
    "variable_deriv(mn_df)\n",
    "################################################################################################################\n",
    "variables = ['dp','dy','ep','de','svar','bm','ntis','tbl','ltr','tms','dfy','dfr','infl']\n",
    "all_variables= ['premium','dp','dy','ep','de','svar','bm','ntis','tbl','ltr','tms','dfy','dfr','infl']\n",
    "variables_sq=variables.copy()\n",
    "variables_sq.extend([item+str('_sq') for item in variables])\n",
    "variables_asy=variables.copy()\n",
    "variables_asy.extend([item+str('_ind') for item in variables])\n",
    "################################################################################################################\n",
    "##Getting final variables from 1927.01~2017.12\n",
    "def variable_transform(df, type_=None):\n",
    "    ori=df.loc[192701:,all_variables]\n",
    "    ind=df.loc[192701:,'indicator']\n",
    "    #X 들\n",
    "    if type_==\"original\" :\n",
    "        ori.loc[:,variables] = StandardScaler().fit_transform(ori.loc[:,variables])\n",
    "        return ori\n",
    "    #X^2 들\n",
    "    elif type_==\"squared\":\n",
    "        output = pd.concat([ori,ori.apply(lambda x: x**2).add_suffix('_sq')],axis=1)\n",
    "        output.loc[:,variables_sq] = StandardScaler().fit_transform(output.loc[:,variables_sq])\n",
    "        return output\n",
    "    #Asymmetric term\n",
    "    elif type_==\"asymmetric\":    \n",
    "        output = pd.concat([ori,ori.apply(lambda x: x*ind).add_suffix('_ind')],axis=1)\n",
    "        output.loc[:,variables_asy] = StandardScaler().fit_transform(output.loc[:,variables_asy])\n",
    "        return output\n",
    "################################################################################################################\n",
    "mn_df_ori=variable_transform(mn_df, type_='original')\n",
    "mn_df_sqr=variable_transform(mn_df, type_='squared')\n",
    "mn_df_asy=variable_transform(mn_df, type_='asymmetric')\n",
    "################################################################################################################\n",
    "# Defining Generator for Time-Series Cross-Validation\n",
    "class timeseries_cv():\n",
    "    \n",
    "    def __init__(self, n_split=3) :\n",
    "        self.n_split = n_split\n",
    "        \n",
    "    def split(self, X, y, group=None) :\n",
    "        n_split = self.n_split\n",
    "        n_fold = n_split + 1\n",
    "        max_len = X.shape[0]\n",
    "        indices = np.arange(max_len)\n",
    "        for index in range(1,n_fold) :\n",
    "            yield (indices[:-index],indices[[-index]])\n",
    "    \n",
    "    def get_n_splits(self, X, y, group=None):\n",
    "        return self.n_split    \n",
    "################################################################################################################\n",
    "# Defining RMSE function for Keras (Ultimately, MSE was used instead)\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "################################################################################################################\n",
    "def mse(y_true, y_pred):\n",
    "    return np.average(np.square(y_true[[0]],y_pred[[0]]))\n",
    "################################################################################################################\n",
    "# Out-of-sample R-2 Coefficient proposed by Campbell and Thompson (2007)\n",
    "def r2_os(y_true,y_pred):\n",
    "    r_value = pd.DataFrame(index=y_pred.index, columns=['numerator','denominator'])\n",
    "    r_value['numerator'] = (y_true - y_pred)**2\n",
    "    r_value['denominator'] = (y_true - y_true.expanding(min_periods=0).mean())**2\n",
    "    r_square = 1 - (r_value['numerator'].sum())/(r_value['denominator'].sum())\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "918ce61acfee84beee93176a3bab70e9ccb4c6d0"
   },
   "source": [
    "### LSTM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "41a3635226f3e135c46dbf96e8a3cadd4f95d285"
   },
   "outputs": [],
   "source": [
    "# MLP Layer Constructing with concatenation of pen-ultimate hidden layer with initial inputs\n",
    "def mlp_merge_builder(hidden_units, input_shape_arg):\n",
    "    main_input = Input(shape=(input_shape_arg,), dtype='float32', name='main_input')\n",
    "    raw_input = Input(shape=(input_shape_arg,), name='concat_input')\n",
    "\n",
    "    for i in range(len(hidden_units)):\n",
    "        # First layer \n",
    "        if len(hidden_units)==1:\n",
    "            x = Dense(hidden_units[0], activation='relu',name=str(hidden_units[0]), kernel_regularizer=regularizers.l2(0.001))(main_input)\n",
    "            x = Dropout(0.5)(x)\n",
    "            x = concatenate([x, raw_input])\n",
    "            break\n",
    "        elif i == 0 :\n",
    "            x = Dense(hidden_units[0], activation='relu',name=str(hidden_units[0]), kernel_regularizer=regularizers.l2(0.001))(main_input)\n",
    "            x = Dropout(0.5)(x)            \n",
    "        # Final layer (concatenation)\n",
    "        elif i == (len(hidden_units)-1):\n",
    "            x = concatenate([x, raw_input])\n",
    "            x = Dense(hidden_units[i], activation='relu', name=str(hidden_units[i]), kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "            x = Dropout(0.5)(x)\n",
    "        # Hidden layer\n",
    "        else:\n",
    "            x = Dense(hidden_units[i], activation='relu', name=str(hidden_units[i]), kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "            x = Dropout(0.5)(x)      \n",
    "    \n",
    "    predictions = Dense(1, activation='linear', name='output')(x)\n",
    "    model = Model(inputs=[main_input, raw_input], outputs=[predictions])\n",
    "    opt = keras.optimizers.SGD(lr=1e-3, decay = 1e-5, nesterov=True, momentum=0.9, clipnorm=5)\n",
    "    model.compile(optimizer=opt, loss='mse',metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# LSTM Layer Constructing without concatenation of pen-ultimate hidden layer with initial inputs\n",
    "def rnn_merge_builder(hidden_units, input_shape_arg):\n",
    "    main_input = Input(shape=(1,input_shape_arg), dtype='float32', name='main_input')\n",
    "    # Case when Only one LSTM layer is used\n",
    "    if len(hidden_units)==1:\n",
    "        x = CuDNNLSTM(hidden_units[0], name=str(hidden_units[0]), kernel_regularizer=regularizers.l2(0.001))(main_input)\n",
    "        x = Dropout(0.2)(x)\n",
    "    # Layer2개 이상일 경우\n",
    "    elif len(hidden_units) != 1:\n",
    "        for i in range(len(hidden_units)):\n",
    "            # 첫 번째 layer \n",
    "            if i == 0 :\n",
    "                x = CuDNNLSTM(hidden_units[0], return_sequences=True, name=str(hidden_units[0]))(main_input)\n",
    "                x = Dropout(0.2)(x)            \n",
    "            # 마지막 layer (concatenation)\n",
    "            elif i == (len(hidden_units)-1):\n",
    "                x = CuDNNLSTM(hidden_units[i], name=str(hidden_units[i]))(x)\n",
    "                x = Dropout(0.2)(x)\n",
    "            # 중간 layer\n",
    "            else:\n",
    "                x = CuDNNLSTM(hidden_units[i], return_sequences=True, name=str(hidden_units[i]))(x)\n",
    "                x = Dropout(0.2)(x)      \n",
    "    \n",
    "    predictions = Dense(1, activation='linear', name='output')(x)\n",
    "    model = Model(inputs=[main_input], outputs=[predictions])\n",
    "    opt = keras.optimizers.RMSprop()\n",
    "    model.compile(optimizer=opt, loss='mse',metrics=['mae'])\n",
    "    \n",
    "    return model    \n",
    "\n",
    "# LSTM Layer Constructing with concatenation of pen-ultimate hidden layer with initial inputs\n",
    "def rnn_merge_builder(hidden_units, input_shape_arg):\n",
    "    main_input = Input(shape=(1,input_shape_arg), dtype='float32', name='main_input')\n",
    "    # With only 1 LSTM layer, the LSTM layers returns output with reduced dimension. Therefore, when concatenating with initial\n",
    "    # input, the dimension discrepancy raises error. To overcome this error, raw_input which is basically copy of initial input\n",
    "    # is also declared with 2-dimensional data. Else, Raw-input is declared with 3-D shape.\n",
    "    if len(hidden_units) ==1:\n",
    "        raw_input = Input(shape=(input_shape_arg,), name='concat_input')\n",
    "    else:\n",
    "        raw_input = Input(shape=(1,input_shape_arg), name='concat_input')\n",
    "    # Case when Only one LSTM layer is used \n",
    "    if len(hidden_units)==1:\n",
    "        x = CuDNNLSTM(hidden_units[0], name=str(hidden_units[0]), kernel_regularizer=regularizers.l2(0.001))(main_input)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = concatenate([x, raw_input])\n",
    "    # Case when more than one LSTM layers are used\n",
    "    elif len(hidden_units) != 1:\n",
    "        for i in range(len(hidden_units)):\n",
    "            # first layer \n",
    "            if i == 0 :\n",
    "                x = CuDNNLSTM(hidden_units[0], return_sequences=True, name=str(hidden_units[0]), kernel_regularizer=regularizers.l2(0.001))(main_input)\n",
    "                x = Dropout(0.5)(x)            \n",
    "            # last layer (concatenation)\n",
    "            elif i == (len(hidden_units)-1):\n",
    "                x = concatenate([x, raw_input])\n",
    "                x = CuDNNLSTM(hidden_units[i], name=str(hidden_units[i]), kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "                x = Dropout(0.5)(x)\n",
    "            # hidden layers\n",
    "            else:\n",
    "                x = CuDNNLSTM(hidden_units[i], return_sequences=True, name=str(hidden_units[i]), kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "                x = Dropout(0.5)(x)      \n",
    "    \n",
    "    predictions = Dense(1, activation='linear', name='output')(x)\n",
    "    model = Model(inputs=[main_input, raw_input], outputs=[predictions])\n",
    "    opt = keras.optimizers.RMSprop()\n",
    "    model.compile(optimizer=opt, loss='mse',metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "ebd77e75705f02ab290570d77a13f1d516b8b1e4"
   },
   "outputs": [],
   "source": [
    "# Function for Calculating Predicted Premium\n",
    "# Suppose to work on expanding and rolling window \n",
    "def nn_prediction(hidden_unit,name,df, type_, variables, window_type, window_range):\n",
    "    ### Variables assignment for calling ###\n",
    "    variables = ['dp','dy','ep','de','svar','bm','ntis','tbl','ltr','tms','dfy','dfr','infl']\n",
    "    window_range = 12 * int(window_range)\n",
    "    if type_=='original':\n",
    "        input_shape_arg = 13\n",
    "    elif type_=='squared':\n",
    "        variables.extend([item+str('_sq') for item in variables])\n",
    "        input_shape_arg = 26\n",
    "    elif type_=='asymmetrical':\n",
    "        variables.extend([item+str('_ind') for item in variables])\n",
    "        input_shape_arg = 26\n",
    "        \n",
    "    pred_premium = pd.DataFrame(index=df.iloc[window_range+1:,:].index,columns=[name+'_{0}_pred'.format(str(hidden_unit)),name+'_{0}_r2'.format(str(hidden_unit))])\n",
    "    \n",
    "    for item in range(1091-window_range): \n",
    "        #item=0 denotes 192701         # item=1091 denotes 201712\n",
    "        #############################################################################################################        \n",
    "        print(item,\"th repeating among {0}\".format((1091-window_range)))\n",
    "        if window_type == 'expanding':\n",
    "            base = 0\n",
    "        else :\n",
    "            base = item\n",
    "        ### Selecting Variables\n",
    "        x_train = (df.iloc[(base):(item+window_range),df.columns.get_indexer(variables)]).values\n",
    "        x_test = (df.iloc[(item+window_range):(item+(window_range+1)),df.columns.get_indexer(variables)]).values\n",
    "        y_train = df['premium'].iloc[base+1:(item+(window_range+1))].values\n",
    "        y_test = df['premium'].iloc[item+(window_range+1):(item+(window_range+2))].values\n",
    "        #############################################################################################################                                  \n",
    "        ### Setting Aside the last data as validation set for Early Stopping\n",
    "        # When believed to be overfitted, turn on Early-Stopping \n",
    "        x_val, x_train = x_train[-1].reshape(1,-1), x_train[:-1]\n",
    "        y_val, y_train = y_train[[-1]], y_train[:-1]\n",
    "        #############################################################################################################        \n",
    "        x_train_concat = x_train.copy()\n",
    "        x_test_concat = x_test.copy()\n",
    "        x_val_concat = x_val.copy()\n",
    "        #############################################################################################################                          \n",
    "        ### Training Selection (LSTM vs MLP)\n",
    "        if name == 'LSTM':\n",
    "            # LSTM Inputs should have Tensor 3D Shape\n",
    "            x_train = x_train.reshape(x_train.shape[0],1,x_train.shape[1])\n",
    "            y_train=y_train.reshape(y_train.shape[0],1)\n",
    "            x_test = x_test.reshape(x_test.shape[0],1,x_test.shape[1])\n",
    "            y_test = y_test.reshape(y_test.shape[0],1)\n",
    "            x_val = x_val.reshape(x_val.shape[0],1,x_val.shape[1])\n",
    "            y_val = y_val.reshape(y_val.shape[0],1)            \n",
    "            # Concatenation에서 Layer1개만 있을 경우 CuDNNLSTM의 output이 축소되어 return 되기에 이와 concat해줄\n",
    "            # raw input도 맞춰주기 위해서 x_train_concat가 조건만족시 reshape 적용하여 차원 확장\n",
    "            if len(hidden_unit) == 1:\n",
    "                pass\n",
    "            elif len(hidden_unit) >= 1:\n",
    "                x_train_concat = x_train_concat.reshape(x_train_concat.shape[0],1,x_train_concat.shape[1])\n",
    "                x_test_concat = x_test_concat.reshape(x_test_concat.shape[0],1,x_test_concat.shape[1])\n",
    "                x_val_concat = x_val_concat.reshape(x_val_concat.shape[0],1,x_val_concat.shape[1])\n",
    "                \n",
    "        elif name == 'MLP':\n",
    "            # MLP does not require input to have Tensor 3D shape(No need to reshape)\n",
    "            pass\n",
    "        #############################################################################################################                                  \n",
    "        ### Model Fitting\n",
    "        early_stopping = EarlyStopping(monitor='val_loss',mode='min', patience=3, restore_best_weights=True)\n",
    "        if name == 'LSTM':\n",
    "            plan = rnn_merge_builder(hidden_unit,input_shape_arg)\n",
    "            batch_size = x_train.shape[0]\n",
    "            # Below history, model_pred, in_sample_pred are used when LSTM isn't construted with concatenation\n",
    "            history = plan.fit({'main_input':x_train},{'output':y_train}, epochs=10, validation_data=([x_val],[y_val]),\n",
    "                             batch_size=256, callbacks=[early_stopping], shuffle=False,verbose=0)\n",
    "            model_pred = plan.predict([x_test])\n",
    "            in_sample_pred = plan.predict([x_train])\n",
    "            \n",
    "        elif name == 'MLP':\n",
    "            plan = mlp_merge_builder(hidden_unit,input_shape_arg)\n",
    "            batch_size = x_train.shape[0]\n",
    "            # Below history, model_pred, in_sample_pred are used when LSTM isn't construted with concatenation\n",
    "            history=plan.fit({'main_input':x_train,'concat_input':x_train_concat},{'output':y_train}, epochs=10, validation_data=([x_val,x_val_concat],[y_val]),\n",
    "                             batch_size=256, callbacks=[early_stopping], shuffle=False,verbose=0)\n",
    "            model_pred = plan.predict([x_test,x_test_concat])\n",
    "            in_sample_pred = plan.predict([x_train,x_train_concat])\n",
    "        #############################################################################################################                                  \n",
    "        #Below history is used when both LSTM and MLP are constructed using concatenation\n",
    "        #history=plan.fit({'main_input':x_train,'concat_input':x_train_concat},{'output':y_train}, epochs=10, \n",
    "        #                 validation_data=([x_val,x_val_concat],[y_val]), batch_size=batch_size, shuffle=False,verbose=0)\n",
    "        #model_pred = plan.predict([x_test,x_test_concat])\n",
    "        #in_sample_pred = np.nan_to_num(plan.predict([x_train,x_train_concat]))\n",
    "        #r2 = r2_score(y_true=y_train,y_pred=in_sample_pred)\n",
    "        #############################################################################################################                                  \n",
    "        ### plotting learning curve\n",
    "#         plt.figure(dpi=150)\n",
    "#         plt.plot(history.history['loss'], label='item_train_loss');\n",
    "#         plt.plot(history.history['val_loss'], label='item_val_loss');\n",
    "#         plt.ylabel('loss');\n",
    "#         plt.xlabel('epoch');\n",
    "#         plt.legend(loc='best');\n",
    "#         plt.show()\n",
    "        #############################################################################################################        \n",
    "        ### Saving the prediction result         \n",
    "        pred_premium.iloc[item,0] = model_pred[0,0]\n",
    "        pred_premium.iloc[item,1] = r2\n",
    "        clear_session()\n",
    "        \n",
    "    return pred_premium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm expanding 35yr (32,16,8) \n",
    "lstm_original_expanding_35yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_ori, 'original', variables, 'expanding', 35)\n",
    "lstm_original_expanding_35yr_32_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_original_expanding_35yr_(32_16_8).csv')\n",
    "lstm_squared_expanding_35yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'expanding', 35)\n",
    "lstm_squared_expanding_35yr_32_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_squared_expanding_35yr_(32_16_8).csv')\n",
    "lstm_asymmetrical_expanding_35yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'expanding', 35)\n",
    "lstm_asymmetrical_expanding_35yr_32_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_asymmetrical_expanding_35yr_(32_16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm expanding 35yr (32,16) \n",
    "lstm_original_expanding_35yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_ori, 'original', variables, 'expanding', 35)\n",
    "lstm_original_expanding_35yr_32_16.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_original_expanding_35yr_(32_16).csv')\n",
    "lstm_squared_expanding_35yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_sqr, 'squared', variables_sq, 'expanding', 35)\n",
    "lstm_squared_expanding_35yr_32_16.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_squared_expanding_35yr_(32_16).csv')\n",
    "lstm_asymmetrical_expanding_35yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'expanding', 35)\n",
    "lstm_asymmetrical_expanding_35yr_32_16.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_asymmetrical_expanding_35yr_(32_16).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm expanding 35yr (16,8) \n",
    "lstm_original_expanding_35yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_ori, 'original', variables, 'expanding', 35)\n",
    "lstm_original_expanding_35yr_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_original_expanding_35yr_(16_8).csv')\n",
    "lstm_squared_expanding_35yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'expanding', 35)\n",
    "lstm_squared_expanding_35yr_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_squared_expanding_35yr_(16_8).csv')\n",
    "lstm_asymmetrical_expanding_35yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'expanding', 35)\n",
    "lstm_asymmetrical_expanding_35yr_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_asymmetrical_expanding_35yr_(16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm moving 35yr (32,16,8) \n",
    "lstm_original_moving_35yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_ori, 'original', variables, 'moving', 35)\n",
    "lstm_original_moving_35yr_32_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_original_moving_35yr_(32_16_8).csv')\n",
    "lstm_squared_moving_35yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 35)\n",
    "lstm_squared_moving_35yr_32_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_squared_moving_35yr_(32_16_8).csv')\n",
    "lstm_asymmetrical_moving_35yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 35)\n",
    "lstm_asymmetrical_moving_35yr_32_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_asymmetrical_moving_35yr_(32_16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm moving 35yr (32,16) \n",
    "lstm_original_moving_35yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_ori, 'original', variables, 'moving', 35)\n",
    "lstm_original_moving_35yr_32_16.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_original_moving_35yr_(32_16).csv')\n",
    "lstm_squared_moving_35yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 35)\n",
    "lstm_squared_moving_35yr_32_16.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_squared_moving_35yr_(32_16).csv')\n",
    "lstm_asymmetrical_moving_35yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 35)\n",
    "lstm_asymmetrical_moving_35yr_32_16.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_asymmetrical_moving_35yr_(32_16).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm moving 35yr (16,8) \n",
    "lstm_original_moving_35yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_ori, 'original', variables, 'moving', 35)\n",
    "lstm_original_moving_35yr_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_original_moving_35yr_(16_8).csv')\n",
    "lstm_squared_moving_35yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 35)\n",
    "lstm_squared_moving_35yr_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_squared_moving_35yr_(16_8).csv')\n",
    "lstm_asymmetrical_moving_35yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 35)\n",
    "lstm_asymmetrical_moving_35yr_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_asymmetrical_moving_35yr_(16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm moving 20yr (32,16,8)\n",
    "lstm_original_moving_20yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_ori, 'original', variables, 'moving', 20)\n",
    "lstm_original_moving_20yr_32_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_original_moving_20yr_(32_16_8).csv')\n",
    "lstm_squared_moving_20yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 20)\n",
    "lstm_squared_moving_20yr_32_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_squared_moving_20yr_(32_16_8).csv')\n",
    "lstm_asymmetrical_moving_20yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 20)\n",
    "lstm_asymmetrical_moving_20yr_32_16_8.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_asymmetrical_moving_20yr_(32_16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm moving 20yr (32,16)\n",
    "lstm_original_moving_20yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_ori, 'original', variables, 'moving', 20)\n",
    "lstm_original_moving_20yr_32_16.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_original_moving_20yr_(32_16).csv')\n",
    "lstm_squared_moving_20yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 20)\n",
    "lstm_squared_moving_20yr_32_16.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_squared_moving_20yr_(32_16).csv')\n",
    "lstm_asymmetrical_moving_20yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 20)\n",
    "lstm_asymmetrical_moving_20yr_32_16.to_csv(r'C:\\Users\\Hightech\\Desktop\\thesis\\result_ver_7\\lstm\\moving\\lstm_asymmetrical_moving_20yr_(32_16).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm moving 20yr (16,8)\n",
    "lstm_original_moving_20yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_ori, 'original', variables, 'moving', 20)\n",
    "lstm_original_moving_20yr_16_8.to_csv(r'C:\\Users\\Home PC\\Desktop\\재무대학원\\재무 대학원\\논문\\result\\result_ver_7\\lstm\\moving\\lstm_original_moving_20yr_(16_8).csv')\n",
    "lstm_squared_moving_20yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 20)\n",
    "lstm_squared_moving_20yr_16_8.to_csv(r'C:\\Users\\Home PC\\Desktop\\재무대학원\\재무 대학원\\논문\\result\\result_ver_7\\lstm\\moving\\lstm_squared_moving_20yr_(16_8).csv')\n",
    "lstm_asymmetrical_moving_20yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 20)\n",
    "lstm_asymmetrical_moving_20yr_16_8.to_csv(r'C:\\Users\\Home PC\\Desktop\\재무대학원\\재무 대학원\\논문\\result\\result_ver_7\\lstm\\moving\\lstm_asymmetrical_moving_20yr_(16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm moving 10yr (32,16,8) \n",
    "lstm_original_moving_10yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_ori, 'original', variables, 'moving', 10)\n",
    "lstm_original_moving_10yr_32_16_8.to_csv(r'C:\\Users\\Home PC\\Desktop\\재무대학원\\재무 대학원\\논문\\result\\result_ver_7\\lstm\\moving\\lstm_original_moving_10yr_(32_16_8).csv')\n",
    "lstm_squared_moving_10yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 10)\n",
    "lstm_squared_moving_10yr_32_16_8.to_csv(r'C:\\Users\\Home PC\\Desktop\\재무대학원\\재무 대학원\\논문\\result\\result_ver_7\\lstm\\moving\\lstm_squared_moving_10yr_(32_16_8).csv')\n",
    "lstm_asymmetrical_moving_10yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 10)\n",
    "lstm_asymmetrical_moving_10yr_32_16_8.to_csv(r'C:\\Users\\Home PC\\Desktop\\재무대학원\\재무 대학원\\논문\\result\\result_ver_7\\lstm\\moving\\lstm_asymmetrical_moving_10yr_(32_16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lstm moving 10yr (32,16) \n",
    "lstm_original_moving_10yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_ori, 'original', variables, 'moving', 10)\n",
    "lstm_original_moving_10yr_32_16.to_csv(r'C:\\Users\\Home PC\\Desktop\\재무대학원\\재무 대학원\\논문\\result\\result_ver_7\\lstm\\moving\\lstm_original_moving_10yr_(32_16).csv')\n",
    "lstm_squared_moving_10yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 10)\n",
    "lstm_squared_moving_10yr_32_16.to_csv(r'C:\\Users\\Home PC\\Desktop\\재무대학원\\재무 대학원\\논문\\result\\result_ver_7\\lstm\\moving\\lstm_squared_moving_10yr_(32_16).csv')\n",
    "lstm_asymmetrical_moving_10yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 10)\n",
    "lstm_asymmetrical_moving_10yr_32_16.to_csv(r'C:\\Users\\Home PC\\Desktop\\재무대학원\\재무 대학원\\논문\\result\\result_ver_7\\lstm\\moving\\lstm_asymmetrical_moving_10yr_(32_16).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lstm moving 10yr (16,8) \n",
    "lstm_original_moving_10yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_ori, 'original', variables, 'moving', 10)\n",
    "lstm_original_moving_10yr_16_8.to_csv(r'C:\\Users\\Home PC\\Desktop\\재무대학원\\재무 대학원\\논문\\result\\result_ver_7\\lstm\\moving\\lstm_original_moving_10yr_(16_8).csv')\n",
    "lstm_squared_moving_10yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 10)\n",
    "lstm_squared_moving_10yr_16_8.to_csv(r'C:\\Users\\Home PC\\Desktop\\재무대학원\\재무 대학원\\논문\\result\\result_ver_7\\lstm\\moving\\lstm_squared_moving_10yr_(16_8).csv')\n",
    "lstm_asymmetrical_moving_10yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 10)\n",
    "lstm_asymmetrical_moving_10yr_16_8.to_csv(r'C:\\Users\\Home PC\\Desktop\\재무대학원\\재무 대학원\\논문\\result\\result_ver_7\\lstm\\moving\\lstm_asymmetrical_moving_10yr_(16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Output only for Google CLoud Datalab\n",
    "# lstm expanding 35yr (32,16,8) \n",
    "lstm_original_expanding_35yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_ori, 'original', variables, 'expanding', 35)\n",
    "lstm_original_expanding_35yr_32_16_8.to_csv('lstm_original_expanding_35yr_(32_16_8).csv')\n",
    "!gsutil cp 'lstm_original_expanding_35yr_(32_16_8).csv' 'gs://master_thesis_storage/lstm/expanding/lstm_original_expanding_35yr_(32_16_8).csv'\n",
    "\n",
    "lstm_squared_expanding_35yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'expanding', 35)\n",
    "lstm_squared_expanding_35yr_32_16_8.to_csv('lstm_squared_expanding_35yr_(32_16_8).csv')\n",
    "!gsutil cp 'lstm_squared_expanding_35yr_(32_16_8).csv' 'gs://master_thesis_storage/lstm/expanding/lstm_squared_expanding_35yr_(32_16_8).csv'\n",
    "\n",
    "lstm_asymmetrical_expanding_35yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'expanding', 35)\n",
    "lstm_asymmetrical_expanding_35yr_32_16_8.to_csv('lstm_asymmetrical_expanding_35yr_(32_16_8).csv')\n",
    "!gsutil cp 'lstm_asymmetrical_expanding_35yr_(32_16_8).csv' 'gs://master_thesis_storage/lstm/expanding/lstm_asymmetrical_expanding_35yr_(32_16_8).csv'\n",
    "\n",
    "# lstm expanding 35yr (32,16) \n",
    "lstm_original_expanding_35yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_ori, 'original', variables, 'expanding', 35)\n",
    "lstm_original_expanding_35yr_32_16.to_csv('lstm_original_expanding_35yr_(32_16).csv')\n",
    "!gsutil cp 'lstm_original_expanding_35yr_(32_16).csv' 'gs://master_thesis_storage/lstm/expanding/lstm_original_expanding_35yr_(32_16).csv'\n",
    "\n",
    "lstm_squared_expanding_35yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_sqr, 'squared', variables_sq, 'expanding', 35)\n",
    "lstm_squared_expanding_35yr_32_16.to_csv('lstm_squared_expanding_35yr_(32_16).csv')\n",
    "!gsutil cp 'lstm_squared_expanding_35yr_(32_16).csv' 'gs://master_thesis_storage/lstm/expanding/lstm_squared_expanding_35yr_(32_16).csv'\n",
    "\n",
    "lstm_asymmetrical_expanding_35yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'expanding', 35)\n",
    "lstm_asymmetrical_expanding_35yr_32_16.to_csv('lstm_asymmetrical_expanding_35yr_(32_16).csv')\n",
    "!gsutil cp 'lstm_asymmetrical_expanding_35yr_(32_16).csv' 'gs://master_thesis_storage/lstm/expanding/lstm_asymmetrical_expanding_35yr_(32_16).csv'\n",
    "\n",
    "# lstm expanding 35yr (16,8) \n",
    "lstm_original_expanding_35yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_ori, 'original', variables, 'expanding', 35)\n",
    "lstm_original_expanding_35yr_16_8.to_csv('lstm_original_expanding_35yr_(16_8).csv')\n",
    "!gsutil cp 'lstm_original_expanding_35yr_(16_8).csv' 'gs://master_thesis_storage/lstm/expanding/lstm_original_expanding_35yr_(16_8).csv'\n",
    "\n",
    "lstm_squared_expanding_35yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'expanding', 35)\n",
    "lstm_squared_expanding_35yr_16_8.to_csv('lstm_squared_expanding_35yr_(16_8).csv')\n",
    "!gsutil cp 'lstm_squared_expanding_35yr_(16_8).csv' 'gs://master_thesis_storage/lstm/expanding/lstm_squared_expanding_35yr_(16_8).csv'\n",
    "\n",
    "lstm_asymmetrical_expanding_35yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'expanding', 35)\n",
    "lstm_asymmetrical_expanding_35yr_16_8.to_csv('lstm_asymmetrical_expanding_35yr_(16_8).csv')\n",
    "!gsutil cp 'lstm_asymmetrical_expanding_35yr_(16_8).csv' 'gs://master_thesis_storage/lstm/expanding/lstm_asymmetrical_expanding_35yr_(16_8).csv'\n",
    "\n",
    "# lstm moving 35yr (32,16,8) \n",
    "lstm_original_moving_35yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_ori, 'original', variables, 'moving', 35)\n",
    "lstm_original_moving_35yr_32_16_8.to_csv('lstm_original_moving_35yr_(32_16_8).csv')\n",
    "!gsutil cp 'lstm_original_moving_35yr_(32_16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_original_moving_35yr_(32_16_8).csv'\n",
    "\n",
    "lstm_squared_moving_35yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 35)\n",
    "lstm_squared_moving_35yr_32_16_8.to_csv('lstm_squared_moving_35yr_(32_16_8).csv')\n",
    "!gsutil cp 'lstm_squared_moving_35yr_(32_16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_squared_moving_35yr_(32_16_8).csv'\n",
    "\n",
    "lstm_asymmetrical_moving_35yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 35)\n",
    "lstm_asymmetrical_moving_35yr_32_16_8.to_csv('lstm_asymmetrical_moving_35yr_(32_16_8).csv')\n",
    "!gsutil cp 'lstm_asymmetrical_moving_35yr_(32_16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_asymmetrical_moving_35yr_(32_16_8).csv'\n",
    "\n",
    "# lstm moving 35yr (32,16) \n",
    "lstm_original_moving_35yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_ori, 'original', variables, 'moving', 35)\n",
    "lstm_original_moving_35yr_32_16.to_csv('lstm_original_moving_35yr_(32_16).csv')\n",
    "!gsutil cp 'lstm_original_moving_35yr_(32_16).csv' 'gs://master_thesis_storage/lstm/moving/lstm_original_moving_35yr_(32_16).csv'\n",
    "\n",
    "lstm_squared_moving_35yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 35)\n",
    "lstm_squared_moving_35yr_32_16.to_csv('lstm_squared_moving_35yr_(32_16).csv')\n",
    "!gsutil cp 'lstm_squared_moving_35yr_(32_16).csv' 'gs://master_thesis_storage/lstm/moving/lstm_squared_moving_35yr_(32_16).csv'\n",
    "\n",
    "lstm_asymmetrical_moving_35yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 35)\n",
    "lstm_asymmetrical_moving_35yr_32_16.to_csv('lstm_asymmetrical_moving_35yr_(32_16).csv')\n",
    "!gsutil cp 'lstm_asymmetrical_moving_35yr_(32_16).csv' 'gs://master_thesis_storage/lstm/moving/lstm_asymmetrical_moving_35yr_(32_16).csv'\n",
    "\n",
    "# lstm moving 35yr (16,8) \n",
    "lstm_original_moving_35yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_ori, 'original', variables, 'moving', 35)\n",
    "lstm_original_moving_35yr_16_8.to_csv('lstm_original_moving_35yr_(16_8).csv')\n",
    "!gsutil cp 'lstm_original_moving_35yr_(16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_original_moving_35yr_(16_8).csv'\n",
    "\n",
    "lstm_squared_moving_35yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 35)\n",
    "lstm_squared_moving_35yr_16_8.to_csv('lstm_squared_moving_35yr_(16_8).csv')\n",
    "!gsutil cp 'lstm_squared_moving_35yr_(16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_squared_moving_35yr_(16_8).csv'\n",
    "\n",
    "lstm_asymmetrical_moving_35yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 35)\n",
    "lstm_asymmetrical_moving_35yr_16_8.to_csv('lstm_asymmetrical_moving_35yr_(16_8).csv')\n",
    "!gsutil cp 'lstm_asymmetrical_moving_35yr_(16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_asymmetrical_moving_35yr_(16_8).csv'\n",
    "\n",
    "# lstm moving 20yr (32,16,8)\n",
    "lstm_original_moving_20yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_ori, 'original', variables, 'moving', 20)\n",
    "lstm_original_moving_20yr_32_16_8.to_csv('lstm_original_moving_20yr_(32_16_8).csv')\n",
    "!gsutil cp 'lstm_original_moving_20yr_(32_16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_original_moving_20yr_(32_16_8).csv'\n",
    "\n",
    "lstm_squared_moving_20yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 20)\n",
    "lstm_squared_moving_20yr_32_16_8.to_csv('lstm_squared_moving_20yr_(32_16_8).csv')\n",
    "!gsutil cp 'lstm_squared_moving_20yr_(32_16_8)csv' 'gs://master_thesis_storage/lstm/moving/lstm_squared_moving_20yr_(32_16_8).csv'\n",
    "\n",
    "lstm_asymmetrical_moving_20yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 20)\n",
    "lstm_asymmetrical_moving_20yr_32_16_8.to_csv('lstm_asymmetrical_moving_20yr_(32_16_8).csv')\n",
    "!gsutil cp 'lstm_asymmetrical_moving_20yr_(32_16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_asymmetrical_moving_20yr_(32_16_8).csv'\n",
    "\n",
    "# lstm moving 20yr (32,16)\n",
    "lstm_original_moving_20yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_ori, 'original', variables, 'moving', 20)\n",
    "lstm_original_moving_20yr_32_16.to_csv('lstm_original_moving_20yr_(32_16).csv')\n",
    "!gsutil cp 'lstm_original_moving_20yr_(32_16).csv' 'gs://master_thesis_storage/lstm/moving/lstm_original_moving_20yr_(32_16).csv'\n",
    "\n",
    "lstm_squared_moving_20yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 20)\n",
    "lstm_squared_moving_20yr_32_16.to_csv('lstm_squared_moving_20yr_(32_16).csv')\n",
    "!gsutil cp 'lstm_squared_moving_20yr_(32_16)csv' 'gs://master_thesis_storage/lstm/moving/lstm_squared_moving_20yr_(32_16).csv'\n",
    "\n",
    "lstm_asymmetrical_moving_20yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 20)\n",
    "lstm_asymmetrical_moving_20yr_32_16.to_csv('lstm_asymmetrical_moving_20yr_(32_16).csv')\n",
    "!gsutil cp 'lstm_asymmetrical_moving_20yr_(32_16).csv' 'gs://master_thesis_storage/lstm/moving/lstm_asymmetrical_moving_20yr_(32_16).csv'\n",
    "\n",
    "# lstm moving 20yr (16,8)\n",
    "lstm_original_moving_20yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_ori, 'original', variables, 'moving', 20)\n",
    "lstm_original_moving_20yr_16_8.to_csv('lstm_original_moving_20yr_(16_8).csv')\n",
    "!gsutil cp 'lstm_original_moving_20yr_(16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_original_moving_20yr_(16_8).csv'\n",
    "\n",
    "lstm_squared_moving_20yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 20)\n",
    "lstm_squared_moving_20yr_16_8.to_csv('lstm_squared_moving_20yr_(16_8).csv')\n",
    "!gsutil cp 'lstm_squared_moving_20yr_(16_8)csv' 'gs://master_thesis_storage/lstm/moving/lstm_squared_moving_20yr_(16_8).csv'\n",
    "\n",
    "lstm_asymmetrical_moving_20yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 20)\n",
    "lstm_asymmetrical_moving_20yr_16_8.to_csv('lstm_asymmetrical_moving_20yr_(16_8).csv')\n",
    "!gsutil cp 'lstm_asymmetrical_moving_20yr_(16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_asymmetrical_moving_20yr_(16_8).csv'\n",
    "\n",
    "# lstm moving 10yr (32,16,8)\n",
    "lstm_original_moving_10yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_ori, 'original', variables, 'moving', 10)\n",
    "lstm_original_moving_10yr_32_16_8.to_csv('lstm_original_moving_10yr_(32_16_8).csv')\n",
    "!gsutil cp 'lstm_original_moving_10yr_(32_16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_original_moving_10yr_(32_16_8).csv'\n",
    "\n",
    "lstm_squared_moving_10yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 10)\n",
    "lstm_squared_moving_10yr_32_16_8.to_csv('lstm_squared_moving_10yr_(32_16_8).csv')\n",
    "!gsutil cp 'lstm_squared_moving_10yr_(32_16_8)csv' 'gs://master_thesis_storage/lstm/moving/lstm_squared_moving_10yr_(32_16_8).csv'\n",
    "\n",
    "lstm_asymmetrical_moving_10yr_32_16_8 = nn_prediction((32,16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 10)\n",
    "lstm_asymmetrical_moving_10yr_32_16_8.to_csv('lstm_asymmetrical_moving_10yr_(32_16_8).csv')\n",
    "!gsutil cp 'lstm_asymmetrical_moving_10yr_(32_16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_asymmetrical_moving_10yr_(32_16_8).csv'\n",
    "\n",
    "# lstm moving 10yr (32,16)\n",
    "lstm_original_moving_10yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_ori, 'original', variables, 'moving', 10)\n",
    "lstm_original_moving_10yr_32_16.to_csv('lstm_original_moving_10yr_(32_16).csv')\n",
    "!gsutil cp 'lstm_original_moving_10yr_(32_16).csv' 'gs://master_thesis_storage/lstm/moving/lstm_original_moving_10yr_(32_16).csv'\n",
    "\n",
    "lstm_squared_moving_10yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 10)\n",
    "lstm_squared_moving_10yr_32_16.to_csv('lstm_squared_moving_10yr_(32_16).csv')\n",
    "!gsutil cp 'lstm_squared_moving_10yr_(32_16)csv' 'gs://master_thesis_storage/lstm/moving/lstm_squared_moving_10yr_(32_16).csv'\n",
    "\n",
    "lstm_asymmetrical_moving_10yr_32_16 = nn_prediction((32,16),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 10)\n",
    "lstm_asymmetrical_moving_10yr_32_16.to_csv('lstm_asymmetrical_moving_10yr_(32_16).csv')\n",
    "!gsutil cp 'lstm_asymmetrical_moving_10yr_(32_16).csv' 'gs://master_thesis_storage/lstm/moving/lstm_asymmetrical_moving_10yr_(32_16).csv'\n",
    "\n",
    "# lstm moving 10yr (16,8)\n",
    "lstm_original_moving_10yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_ori, 'original', variables, 'moving', 10)\n",
    "lstm_original_moving_10yr_16_8.to_csv('lstm_original_moving_10yr_(16_8).csv')\n",
    "!gsutil cp 'lstm_original_moving_10yr_(16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_original_moving_10yr_(16_8).csv'\n",
    "\n",
    "lstm_squared_moving_10yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_sqr, 'squared', variables_sq, 'moving', 10)\n",
    "lstm_squared_moving_10yr_16_8.to_csv('lstm_squared_moving_10yr_(16_8).csv')\n",
    "!gsutil cp 'lstm_squared_moving_10yr_(16_8)csv' 'gs://master_thesis_storage/lstm/moving/lstm_squared_moving_10yr_(16_8).csv'\n",
    "\n",
    "lstm_asymmetrical_moving_10yr_16_8 = nn_prediction((16,8),'LSTM',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 10)\n",
    "lstm_asymmetrical_moving_10yr_16_8.to_csv('lstm_asymmetrical_moving_10yr_(16_8).csv')\n",
    "!gsutil cp 'lstm_asymmetrical_moving_10yr_(16_8).csv' 'gs://master_thesis_storage/lstm/moving/lstm_asymmetrical_moving_10yr_(16_8).csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cf10193aecb166bf79d0a2fa7becf37a85e76d2"
   },
   "outputs": [],
   "source": [
    "# NN Expanding 35yr (32,16,8) \n",
    "nn_original_expanding_35yr_32_16_8 = nn_prediction((32,16,8),'MLP',mn_df_ori, 'original', variables, 'expanding', 35)\n",
    "nn_original_expanding_35yr_32_16_8.to_csv('nn_original_expanding_35yr_(32_16_8).csv')\n",
    "nn_squared_expanding_35yr_32_16_8 = nn_prediction((32,16,8),'MLP',mn_df_sqr, 'squared', variables_sq, 'expanding', 35)\n",
    "nn_squared_expanding_35yr_32_16_8.to_csv('nn_squared_expanding_35yr_(32_16_8).csv')\n",
    "nn_asymmetrical_expanding_35yr_32_16_8 = nn_prediction((32,16,8),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'expanding', 35)\n",
    "nn_asymmetrical_expanding_35yr_32_16_8.to_csv('nn_asymmetrical_expanding_35yr_(32_16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "efa7153662ac8ae4d63b62bb250f1f0239727745"
   },
   "outputs": [],
   "source": [
    "# NN Expanding 35yr (16,8,4)  \n",
    "nn_original_expanding_35yr_16_8_4 = nn_prediction((16,8,4),'MLP',mn_df_ori, 'original', variables, 'expanding', 35)\n",
    "nn_original_expanding_35yr_16_8_4.to_csv('nn_original_expanding_35yr_(16_8_4).csv')\n",
    "nn_squared_expanding_35yr_16_8_4 = nn_prediction((16,8,4),'MLP',mn_df_sqr, 'squared', variables_sq, 'expanding', 35)\n",
    "nn_squared_expanding_35yr_16_8_4.to_csv('nn_squared_expanding_35yr_(16_8_4).csv')\n",
    "nn_asymmetrical_expanding_35yr_16_8_4 = nn_prediction((16,8,4),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'expanding', 35)\n",
    "nn_asymmetrical_expanding_35yr_16_8_4.to_csv('nn_asymmetrical_expanding_35yr_(16_8_4).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15ee7829985874b23eaa10b1f7a562d97a7e8533"
   },
   "outputs": [],
   "source": [
    "# NN Expanding 35yr (16,8)  \n",
    "nn_original_expanding_35yr_16_8 = nn_prediction((16,8),'MLP',mn_df_ori, 'original', variables, 'expanding', 35)\n",
    "nn_original_expanding_35yr_16_8.to_csv('nn_original_expanding_35yr_(16_8).csv')\n",
    "nn_squared_expanding_35yr_16_8 = nn_prediction((16,8),'MLP',mn_df_sqr, 'squared', variables_sq, 'expanding', 35)\n",
    "nn_squared_expanding_35yr_16_8.to_csv('nn_squared_expanding_35yr_(16_8).csv')\n",
    "nn_asymmetrical_expanding_35yr_16_8 = nn_prediction((16,8),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'expanding', 35)\n",
    "nn_asymmetrical_expanding_35yr_16_8.to_csv('nn_asymmetrical_expanding_35yr_(16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b47094c7c3ba558d2f978e96a53af05a9f49b15"
   },
   "outputs": [],
   "source": [
    "# NN Expanding 35yr (16)  \n",
    "nn_original_expanding_35yr_16 = nn_prediction((16,),'MLP',mn_df_ori, 'original', variables, 'expanding', 35)\n",
    "nn_original_expanding_35yr_16.to_csv('nn_original_expanding_35yr_(16).csv')\n",
    "nn_squared_expanding_35yr_16 = nn_prediction((16,),'MLP',mn_df_sqr, 'squared', variables_sq, 'expanding', 35)\n",
    "nn_squared_expanding_35yr_16.to_csv('nn_squared_expanding_35yr_(16).csv')\n",
    "nn_asymmetrical_expanding_35yr_16 = nn_prediction((16,),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'expanding', 35)\n",
    "nn_asymmetrical_expanding_35yr_16.to_csv('nn_asymmetrical_expanding_35yr_(16).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "085160139503d32730db4ce81b72d20082dbbdff"
   },
   "outputs": [],
   "source": [
    "# NN moving 35yr (32,16,8)  \n",
    "nn_original_moving_35yr_32_16_8 = nn_prediction((32,16,8),'MLP',mn_df_ori, 'original', variables, 'moving', 35)\n",
    "nn_original_moving_35yr_32_16_8.to_csv(r'nn_original_moving_35yr_(32_16_8).csv')\n",
    "nn_squared_moving_35yr_32_16_8 = nn_prediction((32,16,8),'MLP',mn_df_sqr, 'squared', variables_sq, 'moving', 35)\n",
    "nn_squared_moving_35yr_32_16_8.to_csv(r'nn_squared_moving_35yr_(32_16_8).csv')\n",
    "nn_asymmetrical_moving_35yr_32_16_8 = nn_prediction((32,16,8),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 35)\n",
    "nn_asymmetrical_moving_35yr_32_16_8.to_csv(r'nn_asymmetrical_moving_35yr_(32_16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c2cb51f05805d4c305d2bffc594ac58331e1829"
   },
   "outputs": [],
   "source": [
    "# NN moving 35yr (16,8,4)  \n",
    "nn_original_moving_35yr_16_8_4 = nn_prediction((16,8,4),'MLP',mn_df_ori, 'original', variables, 'moving', 35)\n",
    "nn_original_moving_35yr_16_8_4.to_csv(r'nn_original_moving_35yr_(16_8_4).csv')\n",
    "nn_squared_moving_35yr_16_8_4 = nn_prediction((16,8,4),'MLP',mn_df_sqr, 'squared', variables_sq, 'moving', 35)\n",
    "nn_squared_moving_35yr_16_8_4.to_csv(r'nn_squared_moving_35yr_(16_8_4).csv')\n",
    "nn_asymmetrical_moving_35yr_16_8_4 = nn_prediction((16,8,4),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 35)\n",
    "nn_asymmetrical_moving_35yr_16_8_4.to_csv(r'nn_asymmetrical_moving_35yr_(16_8_4).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "afe971320075a708b41069895430c493507db461"
   },
   "outputs": [],
   "source": [
    "# NN moving 35yr (16,8)  \n",
    "nn_original_moving_35yr_16_8 = nn_prediction((16,8),'MLP',mn_df_ori, 'original', variables, 'moving', 35)\n",
    "nn_original_moving_35yr_16_8.to_csv(r'nn_original_moving_35yr_(16_8).csv')\n",
    "nn_squared_moving_35yr_16_8 = nn_prediction((16,8),'MLP',mn_df_sqr, 'squared', variables_sq, 'moving', 35)\n",
    "nn_squared_moving_35yr_16_8.to_csv(r'nn_squared_moving_35yr_(16_8).csv')\n",
    "nn_asymmetrical_moving_35yr_16_8 = nn_prediction((16,8),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 35)\n",
    "nn_asymmetrical_moving_35yr_16_8.to_csv(r'nn_asymmetrical_moving_35yr_(16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7aa4df1fc76d0f1c2f4171a45f5f79355c1e4fee"
   },
   "outputs": [],
   "source": [
    "# NN moving 35yr (16)  \n",
    "nn_original_moving_35yr_16 = nn_prediction((16,),'MLP',mn_df_ori, 'original', variables, 'moving', 35)\n",
    "nn_original_moving_35yr_16.to_csv(r'nn_original_moving_35yr_(16).csv')\n",
    "nn_squared_moving_35yr_16 = nn_prediction((16,),'MLP',mn_df_sqr, 'squared', variables_sq, 'moving', 35)\n",
    "nn_squared_moving_35yr_16.to_csv(r'nn_squared_moving_35yr_(16).csv')\n",
    "nn_asymmetrical_moving_35yr_16 = nn_prediction((16,),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 35)\n",
    "nn_asymmetrical_moving_35yr_16.to_csv(r'nn_asymmetrical_moving_35yr_(16).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "967db109de41e9dc2cc7d220241ae388266a961e"
   },
   "outputs": [],
   "source": [
    "# NN moving 20yr (32,16,8)  \n",
    "nn_original_moving_20yr_32_16_8 = nn_prediction((32,16,8),'MLP',mn_df_ori, 'original', variables, 'moving', 20)\n",
    "nn_original_moving_20yr_32_16_8.to_csv(r'nn_original_moving_20yr_(32_16_8).csv')\n",
    "nn_squared_moving_20yr_32_16_8 = nn_prediction((32,16,8),'MLP',mn_df_sqr, 'squared', variables_sq, 'moving', 20)\n",
    "nn_squared_moving_20yr_32_16_8.to_csv(r'nn_squared_moving_20yr_(32_16_8).csv')\n",
    "nn_asymmetrical_moving_20yr_32_16_8 = nn_prediction((32,16,8),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 20)\n",
    "nn_asymmetrical_moving_20yr_32_16_8.to_csv(r'nn_asymmetrical_moving_20yr_(32_16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2210374febad61e120d49c909cbc5e59f6ce6d4c"
   },
   "outputs": [],
   "source": [
    "# NN moving 20yr (16,8,4) \n",
    "nn_original_moving_20yr_16_8_4 = nn_prediction((16,8,4),'MLP',mn_df_ori, 'original', variables, 'moving', 20)\n",
    "nn_original_moving_20yr_16_8_4.to_csv(r'nn_original_moving_20yr_(16_8_4).csv')\n",
    "nn_squared_moving_20yr_16_8_4 = nn_prediction((16,8,4),'MLP',mn_df_sqr, 'squared', variables_sq, 'moving', 20)\n",
    "nn_squared_moving_20yr_16_8_4.to_csv(r'nn_squared_moving_20yr_(16_8_4).csv')\n",
    "nn_asymmetrical_moving_20yr_16_8_4 = nn_prediction((16,8,4),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 20)\n",
    "nn_asymmetrical_moving_20yr_16_8_4.to_csv(r'nn_asymmetrical_moving_20yr_(16_8_4).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c1cf6ae552719f3ade866ccea495bbfd13666a0c"
   },
   "outputs": [],
   "source": [
    "# NN moving 20yr (16-8) \n",
    "nn_original_moving_20yr_16_8 = nn_prediction((16,8),'MLP',mn_df_ori, 'original', variables, 'moving', 20)\n",
    "nn_original_moving_20yr_16_8.to_csv(r'nn_original_moving_20yr_(16_8).csv')\n",
    "nn_squared_moving_20yr_16_8 = nn_prediction((16,8),'MLP',mn_df_sqr, 'squared', variables_sq, 'moving', 20)\n",
    "nn_squared_moving_20yr_16_8.to_csv(r'nn_squared_moving_20yr_(16_8).csv')\n",
    "nn_asymmetrical_moving_20yr_16_8 = nn_prediction((16,8),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 20)\n",
    "nn_asymmetrical_moving_20yr_16_8.to_csv(r'nn_asymmetrical_moving_20yr_(16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9112f8159f368d31df1290b14887d1ef8346f41b"
   },
   "outputs": [],
   "source": [
    "# NN moving 20yr (16) \n",
    "nn_original_moving_20yr_16 = nn_prediction((16,),'MLP',mn_df_ori, 'original', variables, 'moving', 20)\n",
    "nn_original_moving_20yr_16.to_csv(r'nn_original_moving_20yr_(16).csv')\n",
    "nn_squared_moving_20yr_16 = nn_prediction((16,),'MLP',mn_df_sqr, 'squared', variables_sq, 'moving', 20)\n",
    "nn_squared_moving_20yr_16.to_csv(r'nn_squared_moving_20yr_(16).csv')\n",
    "nn_asymmetrical_moving_20yr_16 = nn_prediction((16,),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 20)\n",
    "nn_asymmetrical_moving_20yr_16.to_csv(r'nn_asymmetrical_moving_20yr_(16).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4bcc7c07afad207b235b81e529a63779ff4c6fb9"
   },
   "outputs": [],
   "source": [
    "# NN moving 10yr (32,16,8) \n",
    "nn_original_moving_10yr_32_16_8 = nn_prediction((32,16,8),'MLP',mn_df_ori, 'original', variables, 'moving', 10)\n",
    "nn_original_moving_10yr_32_16_8.to_csv(r'nn_original_moving_10yr_(32_16_8).csv')\n",
    "nn_squared_moving_10yr_32_16_8 = nn_prediction((32,16,8),'MLP',mn_df_sqr, 'squared', variables_sq, 'moving', 10)\n",
    "nn_squared_moving_10yr_32_16_8.to_csv(r'nn_squared_moving_10yr_(32_16_8).csv')\n",
    "nn_asymmetrical_moving_10yr_32_16_8 = nn_prediction((32,16,8),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 10)\n",
    "nn_asymmetrical_moving_10yr_32_16_8.to_csv(r'nn_asymmetrical_moving_10yr_(32_16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91ccfa4d42cd00eebeb0361e80444e3bf4fc573b"
   },
   "outputs": [],
   "source": [
    "# NN moving 10yr (16,8,4) \n",
    "nn_original_moving_10yr_16_8_4 = nn_prediction((16,8,4),'MLP',mn_df_ori, 'original', variables, 'moving', 10)\n",
    "nn_original_moving_10yr_16_8_4.to_csv(r'nn_original_moving_10yr_(16_8_4).csv')\n",
    "nn_squared_moving_10yr_16_8_4 = nn_prediction((16,8,4),'MLP',mn_df_sqr, 'squared', variables_sq, 'moving', 10)\n",
    "nn_squared_moving_10yr_16_8_4.to_csv(r'nn_squared_moving_10yr_(16_8_4).csv')\n",
    "nn_asymmetrical_moving_10yr_16_8_4 = nn_prediction((16,8,4),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 10)\n",
    "nn_asymmetrical_moving_10yr_16_8_4.to_csv(r'nn_asymmetrical_moving_10yr_(16_8_4).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb32adbd1ec48fafc368be16f2ceb3635f34c827"
   },
   "outputs": [],
   "source": [
    "# NN moving 10yr (16,8) \n",
    "nn_original_moving_10yr_16_8 = nn_prediction((16,8),'MLP',mn_df_ori, 'original', variables, 'moving', 10)\n",
    "nn_original_moving_10yr_16_8.to_csv(r'nn_original_moving_10yr_(16_8).csv')\n",
    "nn_squared_moving_10yr_16_8 = nn_prediction((16,8),'MLP',mn_df_sqr, 'squared', variables_sq, 'moving', 10)\n",
    "nn_squared_moving_10yr_16_8.to_csv(r'nn_squared_moving_10yr_(16_8).csv')\n",
    "nn_asymmetrical_moving_10yr_16_8 = nn_prediction((16,8),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 10)\n",
    "nn_asymmetrical_moving_10yr_16_8.to_csv(r'nn_asymmetrical_moving_10yr_(16_8).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a88f9c673799a51e38e056b532bc42b5b6f430d"
   },
   "outputs": [],
   "source": [
    "# NN moving 10yr (16) \n",
    "nn_original_moving_10yr_16 = nn_prediction((16,),'MLP',mn_df_ori, 'original', variables, 'moving', 10)\n",
    "nn_original_moving_10yr_16.to_csv(r'nn_original_moving_10yr_(16).csv')\n",
    "nn_squared_moving_10yr_16 = nn_prediction((16,),'MLP',mn_df_sqr, 'squared', variables_sq, 'moving', 10)\n",
    "nn_squared_moving_10yr_16.to_csv(r'nn_squared_moving_10yr_(16).csv')\n",
    "nn_asymmetrical_moving_10yr_16 = nn_prediction((16,),'MLP',mn_df_asy, 'asymmetrical', variables_asy, 'moving', 10)\n",
    "nn_asymmetrical_moving_10yr_16.to_csv(r'nn_asymmetrical_moving_10yr_(16).csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
